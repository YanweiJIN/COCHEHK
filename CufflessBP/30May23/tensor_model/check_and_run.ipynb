{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import scipy.signal as signal\n",
    "import scipy.io as sio\n",
    "import scipy.stats\n",
    "from scipy.fft import fft\n",
    "import neurokit2 as nk\n",
    "import heartpy as hp\n",
    "import nolds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/jinyanwei/Desktop/BP_Model/Jinyw_code/')\n",
    "from read_data import open_data\n",
    "from filter_and_clean_data import clean_data\n",
    "from segment_and_features import features_data\n",
    "from random_forest import run_random_forest\n",
    "\n",
    "all_data = open_data('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/Part_1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = pd.DataFrame()\n",
    "for patient_number in range(1):\n",
    "    if len(all_data[patient_number]) > 18000 :  # 5min-300beats-18000sample at least\n",
    "        clean_data(all_data[patient_number], patient_number)\n",
    "        features_data(\"/Users/jinyanwei/Desktop/BP_Model/Model_record/cleaned_data\", patient_number)\n",
    "        features_file = f'/Users/jinyanwei/Desktop/BP_Model/Model_record/features_data/Part1_feature{patient_number}.csv'\n",
    "        if not os.path.exists(features_file):\n",
    "            continue       \n",
    "        data_ready = pd.concat([data_ready, pd.read_csv(features_file)])\n",
    "run_random_forest(data_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 小文件打开mat\n",
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "\n",
    "data_path=\"/Users/jinyanwei/Desktop/BP_Model/Data/Cuffless_BP_Estimation/part_10.mat\"\n",
    "data = scio.loadmat(data_path)\n",
    "len(data['p'][0])\n",
    "all_patients = list(data['p'][0])\n",
    "df = pd.DataFrame(all_patients[0]).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/Part_1.mat', 'r') as file:\n",
    "    print(list(file.keys()))\n",
    "    references = np.array(file[list(file.keys())[1]]) #### Access a specific variable and convert it to a NumPy array   \n",
    "    # Dereference the objects and store them in a list\n",
    "    data = []\n",
    "    for ref in references.flat:\n",
    "        dereferenced_object = np.array(file[ref])\n",
    "        data.append(dereferenced_object)  \n",
    "#### Show the shape of the data\n",
    "for i, array in enumerate(data):\n",
    "    print(f\"Shape of data[{i}]: {array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[0], columns=(('PPG','BP','ECG')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[0], columns=(('PPG','BP','ECG')))\n",
    "ppg_data = df['PPG']\n",
    "bp_data = df['BP']\n",
    "ecg_data = df['ECG']\n",
    "\n",
    "## Filter signals\n",
    "sampling_rate = 125\n",
    "ppg_filtered = nk.signal_filter(ppg_data, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=sampling_rate)\n",
    "ecg_filtered = nk.signal_filter(ecg_data, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=sampling_rate)\n",
    "filtered_df = df\n",
    "filtered_df['PPG'], filtered_df['ECG'] = ppg_filtered, ecg_filtered\n",
    "#### show the filtered PPG and ECG signals\n",
    "ppg_df = pd.DataFrame(columns=(('PPG_original', 'PPG_filtered')))\n",
    "ppg_df['PPG_original'] = ppg_data\n",
    "ppg_df['PPG_filtered'] = ppg_filtered\n",
    "display(ppg_df)\n",
    "figPPG = px.line(ppg_df)\n",
    "figPPG.show()\n",
    "ecg_df = pd.DataFrame(columns=(('ECG_original', 'ECG_filtered')))\n",
    "ecg_df['ECG_original'] = ecg_data\n",
    "ecg_df['ECG_filtered'] = ecg_filtered\n",
    "display(ecg_df)\n",
    "figECG = px.line(ecg_df)\n",
    "figECG.show()\n",
    "\n",
    "## Clean data: make every beat only have one PPG/BP peak\n",
    "#### Find ECG R-peaks\n",
    "ecgpeaks, _ = signal.find_peaks(ecg_filtered, distance=sampling_rate//2.5)\n",
    "print(ecgpeaks, len(ecgpeaks))\n",
    "plt.figure(figsize=(50, 10))\n",
    "for index in ecgpeaks:\n",
    "    plt.scatter(index, ecg_filtered[index], marker=\"*\")\n",
    "plt.plot(ecg_filtered)\n",
    "plt.show()\n",
    "\n",
    "#### Make sure onle one PPG peak and one BP peak between two adjacent ECG R-peaks\n",
    "cleaned_df = pd.DataFrame()\n",
    "sum_beats = 0\n",
    "times_recorder = []\n",
    "for R_peak_number in range(len(ecgpeaks)-1):\n",
    "    sum_beats += 1\n",
    "    if ecg_filtered[ecgpeaks[R_peak_number]] > 0.2 and ecg_filtered[ecgpeaks[R_peak_number + 1]] > 0.2: # make sure the peaks are R-peak\n",
    "        onebeat_ppgpeak, _ = signal.find_peaks(ppg_filtered[ecgpeaks[R_peak_number]:ecgpeaks[R_peak_number + 1]], distance = sampling_rate//2.5)\n",
    "        onebeat_bppeak, _ = signal.find_peaks(bp_data[ecgpeaks[R_peak_number]:ecgpeaks[R_peak_number + 1]], distance = sampling_rate//2.5)\n",
    "        if len(onebeat_ppgpeak) == 1 and ppg_filtered[ecgpeaks[R_peak_number] + onebeat_ppgpeak] > 0 and len(onebeat_bppeak) == 1 : # make sure only one BP signal for one beat \n",
    "            cleaned_df = pd.concat([cleaned_df, filtered_df[ecgpeaks[R_peak_number]:ecgpeaks[R_peak_number + 1]]])\n",
    "            times_recorder.append(sum_beats)                \n",
    "\n",
    "#### Show  original cleaned data:\n",
    "print('All beats: ', sum_beats, ', Reserved beats: ', len(times_recorder))\n",
    "display(cleaned_df)\n",
    "figcleaned = px.line(cleaned_df)\n",
    "figcleaned.show()\n",
    "\n",
    "#### Reset indexs:\n",
    "cleaned_df = cleaned_df.reset_index()\n",
    "#### Show final cleaned data:\n",
    "display(cleaned_df)\n",
    "figcleaned = px.line(cleaned_df)\n",
    "figcleaned.show()\n",
    "\n",
    "## Segment signals from R-peak to get data of each beat.\n",
    "df = cleaned_df\n",
    "ppg_data = df['PPG']\n",
    "bp_data = df['BP']\n",
    "ecg_data = df['ECG']\n",
    "sampling_rate = 125\n",
    "ecgpeaks, _ = signal.find_peaks(ecg_data, distance=sampling_rate//2.5)\n",
    "ppg_segments, ecg_segments, SBPlist, DBPlist, bplist = [], [], [], [], []\n",
    "for peak_number in range(1, len(ecgpeaks)-2):    # data will be more stable from the second R-peak\n",
    "    ppg_segments.append(ppg_data[ecgpeaks[peak_number]:ecgpeaks[peak_number + 1]].values)\n",
    "    ecg_segments.append(ecg_data[ecgpeaks[peak_number]:ecgpeaks[peak_number + 1]].values)\n",
    "    bplist = bp_data[ecgpeaks[peak_number]:ecgpeaks[peak_number+1]]\n",
    "    SBPlist.append(max(bplist))\n",
    "    DBPlist.append(min(bplist))\n",
    "## Extract features of PPG and ECG.\n",
    "\n",
    "#### Def features:\n",
    "from numpy.fft import fft\n",
    "def extract_ppg_features(signal):\n",
    "    #### Time domain features\n",
    "    mean = np.mean(signal)\n",
    "    std_dev = np.std(signal)\n",
    "    skewness = scipy.stats.skew(signal)\n",
    "    kurtosis = scipy.stats.kurtosis(signal)\n",
    "    #### Frequency domain features\n",
    "    fft_values = fft(signal)\n",
    "    power_spectrum = np.abs(fft_values)**2\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    low_freq_power = np.sum(power_spectrum[:len(power_spectrum)//2]) / total_power\n",
    "    high_freq_power = np.sum(power_spectrum[len(power_spectrum)//2:]) / total_power\n",
    "    ppg_features = {\n",
    "        'ppg_mean': mean,\n",
    "        'ppg_std_dev': std_dev,\n",
    "        'ppg_skewness': skewness,\n",
    "        'ppg_kurtosis': kurtosis,\n",
    "        'ppg_low_freq_power': low_freq_power,\n",
    "        'ppg_high_freq_power': high_freq_power\n",
    "    }\n",
    "    return ppg_features\n",
    "\n",
    "def extract_ecg_features(signal):\n",
    "    # Time domain features\n",
    "    mean = np.mean(signal)\n",
    "    std_dev = np.std(signal)\n",
    "    skewness = scipy.stats.skew(signal)\n",
    "    kurtosis = scipy.stats.kurtosis(signal)\n",
    "    # Frequency domain features\n",
    "    fft_values = fft(signal)\n",
    "    power_spectrum = np.abs(fft_values)**2\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    low_freq_power = np.sum(power_spectrum[:len(power_spectrum)//2]) / total_power\n",
    "    high_freq_power = np.sum(power_spectrum[len(power_spectrum)//2:]) / total_power\n",
    "    ecg_features = {\n",
    "        'ecg_mean': mean,\n",
    "        'ecg_std_dev': std_dev,\n",
    "        'ecg_skewness': skewness,\n",
    "        'ecg_kurtosis': kurtosis,\n",
    "        'ecg_low_freq_power': low_freq_power,\n",
    "        'ecg_high_freq_power': high_freq_power\n",
    "    }\n",
    "    return ecg_features\n",
    "#### Get features and save to csv:\n",
    "ppg_feature_list = [extract_ppg_features(ppg_segment) for ppg_segment in ppg_segments]\n",
    "ecg_feature_list = [extract_ecg_features(ecg_segment) for ecg_segment in ecg_segments]\n",
    "features_df = pd.concat([pd.DataFrame(ppg_feature_list), pd.DataFrame(ecg_feature_list), pd.DataFrame({'SBP': SBPlist, 'DBP':DBPlist})], axis=1)\n",
    "display(features_df)\n",
    "\n",
    "#### Estimate BP\n",
    "df = features_df\n",
    "X_scaled = df.iloc[:, 1:-2].values\n",
    "y_bp = df.iloc[:, -2:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_bp, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "result_bp = pd.DataFrame(columns=['SBP_actu','SBP_pred','DBP_actu','DBP_pred'])\n",
    "result_bp['SBP_actu'] = y_test['SBP']\n",
    "result_bp['DBP_actu'] = y_test['DBP']\n",
    "result_bp['SBP_pred'] = y_pred[:,0]\n",
    "result_bp['DBP_pred'] = y_pred[:,1]\n",
    "result_bp = result_bp.sort_index()\n",
    "\n",
    "rmse_sbp = metrics.mean_squared_error(result_bp['SBP_actu'], result_bp['SBP_pred'])**0.5\n",
    "rmse_dbp = metrics.mean_squared_error(result_bp['DBP_actu'], result_bp['DBP_pred'])**0.5\n",
    "mae_sbp = metrics.mean_absolute_error(result_bp['SBP_actu'], result_bp['SBP_pred'])\n",
    "mae_dbp = metrics.mean_absolute_error(result_bp['DBP_actu'], result_bp['DBP_pred'])\n",
    "\n",
    "print(f'{len(y_train)} beats to train and {len(y_test)} beats to test.', \n",
    "    '\\n'f\"Root mean squared error for SBP: {rmse_sbp:.3f}\", \n",
    "    '\\n'f\"Root mean squared error for DBP: {rmse_dbp:.3f}\", \n",
    "    '\\n'f\"Mean absolute error for SBP: {mae_sbp:.3f}\", \n",
    "    '\\n'f\"Mean absolute error for DBP: {mae_dbp:.3f}\"\n",
    "    )\n",
    "def write_record_totxt():\n",
    "    file_handle = open('/Users/jinyanwei/Desktop/BP_Model/Model_record/random_forest_result.txt', mode='a')\n",
    "    file_handle.write(f'{len(y_train)} beats to train and {len(y_test)} beats to test.')\n",
    "    file_handle.write('\\n')\n",
    "    file_handle.write(f\"Root mean squared error for SBP: {rmse_sbp:.3f}\")\n",
    "    file_handle.write('\\n')\n",
    "    file_handle.write(f\"Root mean squared error for DBP: {rmse_dbp:.3f}\")\n",
    "    file_handle.write('\\n')\n",
    "    file_handle.write(f\"Mean absolute error for SBP: {mae_sbp:.3f}\")\n",
    "    file_handle.write('\\n')\n",
    "    file_handle.write(f\"Mean absolute error for DBP: {mae_dbp:.3f}\")\n",
    "    file_handle.write('\\n')\n",
    "    file_handle.write('\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "#### Draw pictures\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.subplot(2, 1, 1)\n",
    "x1 = np.array((range(len(result_bp))))\n",
    "sbp1 = np.array(result_bp['SBP_pred'])\n",
    "sbp2 = np.array(result_bp['SBP_actu'])\n",
    "plt.plot(x1, sbp1, label='SBP_pred')\n",
    "plt.plot(x1, sbp2, label='SBP_actu')\n",
    "plt.title('SBP')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "x2 = x1\n",
    "dbp1 = np.array(result_bp['DBP_pred'])\n",
    "dbp2 = np.array(result_bp['DBP_actu'])\n",
    "plt.plot(x2, dbp1, label='DBP_pred')\n",
    "plt.plot(x2, dbp2, label='DBP_actu')\n",
    "plt.title('DBP')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
